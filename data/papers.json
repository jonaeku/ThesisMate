[
  {
    "title": "Lecture Notes: Neural Network Architectures",
    "authors": [
      "Evelyn Herberg"
    ],
    "abstract": "These lecture notes provide an overview of Neural Network architectures from a mathematical point of view. Especially, Machine Learning with Neural Networks is seen as an optimization problem. Covered are an introduction to Neural Networks and the following architectures: Feedforward Neural Network, Convolutional Neural Network, ResNet, and Recurrent Neural Network.",
    "url": "http://arxiv.org/abs/2304.05133v2",
    "bibtex": "@article{lecture2023,\n  title={Lecture Notes: Neural Network Architectures},\n  author={Evelyn Herberg},\n  year={2023},\n  url={http://arxiv.org/abs/2304.05133v2},\n  note={arXiv preprint}\n}",
    "year": 2023,
    "relevance_score": 0.0,
    "source": "arxiv",
    "citation_count": null,
    "doi": null
  },
  {
    "title": "Self-Organizing Multilayered Neural Networks of Optimal Complexity",
    "authors": [
      "V. Schetinin"
    ],
    "abstract": "The principles of self-organizing the neural networks of optimal complexity is considered under the unrepresentative learning set. The method of self-organizing the multi-layered neural networks is offered and used to train the logical neural networks which were applied to the medical diagnostics.",
    "url": "http://arxiv.org/abs/cs/0504056v1",
    "bibtex": "@article{self-organizing2005,\n  title={Self-Organizing Multilayered Neural Networks of Optimal Complexity},\n  author={V. Schetinin},\n  year={2005},\n  url={http://arxiv.org/abs/cs/0504056v1},\n  note={arXiv preprint}\n}",
    "year": 2005,
    "relevance_score": 0.0,
    "source": "arxiv",
    "citation_count": null,
    "doi": null
  },
  {
    "title": "Neural Network Processing Neural Networks: An efficient way to learn   higher order functions",
    "authors": [
      "Firat Tuna"
    ],
    "abstract": "Functions are rich in meaning and can be interpreted in a variety of ways. Neural networks were proven to be capable of approximating a large class of functions[1]. In this paper, we propose a new class of neural networks called \"Neural Network Processing Neural Networks\" (NNPNNs), which inputs neural networks and numerical values, instead of just numerical values. Thus enabling neural networks to represent and process rich structures.",
    "url": "http://arxiv.org/abs/1911.05640v2",
    "bibtex": "@article{neural2019,\n  title={Neural Network Processing Neural Networks: An efficient way to learn   higher order functions},\n  author={Firat Tuna},\n  year={2019},\n  url={http://arxiv.org/abs/1911.05640v2},\n  note={arXiv preprint}\n}",
    "year": 2019,
    "relevance_score": 0.0,
    "source": "arxiv",
    "citation_count": null,
    "doi": null
  },
  {
    "title": "Neural Networks",
    "authors": [],
    "abstract": "Abstract not available",
    "url": "https://doi.org/10.1016/s0893-6080(13)00287-6",
    "bibtex": "@article{neural2014,\n  title={Neural Networks},\n  author={Unknown},\n  year={2014},\n  journal={Neural Networks},\n  doi={10.1016/s0893-6080(13)00287-6}\n}",
    "year": 2014,
    "relevance_score": 0.0,
    "source": "crossref",
    "citation_count": null,
    "doi": "10.1016/s0893-6080(13)00287-6"
  }
]