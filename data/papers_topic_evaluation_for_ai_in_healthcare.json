[
  {
    "title": "IAC: A Framework for Enabling Patient Agency in the Use of AI-Enabled   Healthcare",
    "authors": [
      "Chinasa T. Okolo",
      "Michelle González Amador"
    ],
    "abstract": "In healthcare, the role of AI is continually evolving, and understanding the challenges its introduction poses on relationships between healthcare providers and patients will require a regulatory and behavioral approach that can provide a guiding base for all users involved. In this paper, we present IAC (Informing, Assessment, and Consent), a framework for evaluating patient response to the introduction of AI-enabled digital technologies in healthcare settings. We justify the need for IAC with a general introduction of the challenges with and perceived relevance of AI in human-welfare-centered fields, with an emphasis on the provision of healthcare. The framework is composed of three core principles that guide how healthcare practitioners can inform patients about the use of AI in their healthcare, how practitioners can assess patients' acceptability and comfortability with the use of AI, and how patient consent can be gained after this process. We propose that the principles composing this framework can be translated into guidelines that improve practitioner-patient relationships and, concurrently, patient agency regarding the use of AI in healthcare while broadening the discourse on this topic.",
    "url": "http://arxiv.org/abs/2111.04456v3",
    "bibtex": "@article{iac:2021,\n  title={IAC: A Framework for Enabling Patient Agency in the Use of AI-Enabled   Healthcare},\n  author={Chinasa T. Okolo and Michelle González Amador},\n  year={2021},\n  url={http://arxiv.org/abs/2111.04456v3},\n  note={arXiv preprint}\n}",
    "year": 2021,
    "relevance_score": 0.5,
    "source": "arxiv",
    "citation_count": null,
    "doi": null
  },
  {
    "title": "Developing a Medical AI Ethics Framework: Integrating Ethical Principles with Healthcare Applications Using Topic Modelling",
    "authors": [
      "Oluwafeyifunmi Olunuga"
    ],
    "abstract": "Abstract not available",
    "url": "https://doi.org/10.22215/etd/2023-15586",
    "bibtex": "@article{developing2024,\n  title={Developing a Medical AI Ethics Framework: Integrating Ethical Principles with Healthcare Applications Using Topic Modelling},\n  author={Oluwafeyifunmi Olunuga},\n  year={2024},\n  doi={10.22215/etd/2023-15586}\n}",
    "year": 2024,
    "relevance_score": 0.5,
    "source": "crossref",
    "citation_count": null,
    "doi": "10.22215/etd/2023-15586"
  },
  {
    "title": "Explainable AI (XAI) in Healthcare - Tools and Regulations",
    "authors": [
      "Paweł Raif",
      "Renata Suchanek-Raif",
      "Ewaryst Tkacz"
    ],
    "abstract": "Abstract not available",
    "url": "https://doi.org/10.1109/ieeeconf58974.2023.10405096",
    "bibtex": "@article{explainable2023,\n  title={Explainable AI (XAI) in Healthcare - Tools and Regulations},\n  author={Paweł Raif and Renata Suchanek-Raif and Ewaryst Tkacz},\n  year={2023},\n  journal={2023 IEEE EMBS Special Topic Conference on Data Science and Engineering in Healthcare, Medicine and Biology},\n  doi={10.1109/ieeeconf58974.2023.10405096}\n}",
    "year": 2023,
    "relevance_score": 0.5,
    "source": "crossref",
    "citation_count": null,
    "doi": "10.1109/ieeeconf58974.2023.10405096"
  },
  {
    "title": "Educating a Responsible AI Workforce: Piloting a Curricular Module on AI   Policy in a Graduate Machine Learning Course",
    "authors": [
      "James Weichert",
      "Hoda Eldardiry"
    ],
    "abstract": "As artificial intelligence (AI) technologies begin to permeate diverse fields-from healthcare to education-consumers, researchers and policymakers are increasingly raising concerns about whether and how AI is regulated. It is therefore reasonable to anticipate that alignment with principles of 'ethical' or 'responsible' AI, as well as compliance with law and policy, will form an increasingly important part of AI development. Yet, for the most part, the conventional computer science curriculum is ill-equipped to prepare students for these challenges. To this end, we seek to explore how new educational content related to AI ethics and AI policy can be integrated into both ethics- and technical-focused courses. This paper describes a two-lecture 'AI policy module' that was piloted in a graduate-level introductory machine learning course in 2024. The module, which includes an in-class active learning game, is evaluated using data from student surveys before and after the lectures, and pedagogical motivations and considerations are discussed. We find that the module is successful in engaging otherwise technically-oriented students on the topic of AI policy, increasing student awareness of the social impacts of a variety of AI technologies and developing student interest in the field of AI regulation.",
    "url": "http://arxiv.org/abs/2502.07931v1",
    "bibtex": "@article{educating2025,\n  title={Educating a Responsible AI Workforce: Piloting a Curricular Module on AI   Policy in a Graduate Machine Learning Course},\n  author={James Weichert and Hoda Eldardiry},\n  year={2025},\n  url={http://arxiv.org/abs/2502.07931v1},\n  note={arXiv preprint}\n}",
    "year": 2025,
    "relevance_score": 0.3333333333333333,
    "source": "arxiv",
    "citation_count": null,
    "doi": null
  },
  {
    "title": "The Strategic Imperative for Healthcare Organizations to Build   Proprietary Foundation Models",
    "authors": [
      "Naresh Tiwari"
    ],
    "abstract": "This paper presents a comprehensive analysis of the strategic imperative for healthcare organizations to develop proprietary foundation models rather than relying exclusively on commercial alternatives. We examine four fundamental considerations driving this imperative: the domain-specific requirements of healthcare data representation, critical data sovereignty and governance considerations unique to healthcare, strategic competitive advantages afforded by proprietary AI infrastructure, and the transformative potential of healthcare-specific foundation models for patient care and organizational operations. Through analysis of empirical evidence, economic frameworks, and organizational case studies, we demonstrate that proprietary multimodal foundation models enable healthcare organizations to achieve superior clinical performance, maintain robust data governance, create sustainable competitive advantages, and accelerate innovation pathways. While acknowledging implementation challenges, we present evidence showing organizations with proprietary AI capabilities demonstrate measurably improved outcomes, faster innovation cycles, and stronger strategic positioning in the evolving healthcare ecosystem. This analysis provides healthcare leaders with a comprehensive framework for evaluating build-versus-buy decisions regarding foundation model implementation, positioning proprietary foundation model development as a cornerstone capability for forward-thinking healthcare organizations.",
    "url": "http://arxiv.org/abs/2506.11412v1",
    "bibtex": "@article{the2025,\n  title={The Strategic Imperative for Healthcare Organizations to Build   Proprietary Foundation Models},\n  author={Naresh Tiwari},\n  year={2025},\n  url={http://arxiv.org/abs/2506.11412v1},\n  note={arXiv preprint}\n}",
    "year": 2025,
    "relevance_score": 0.3333333333333333,
    "source": "arxiv",
    "citation_count": null,
    "doi": null
  },
  {
    "title": "TOPIC 7 (the older person and improving care): evaluation",
    "authors": [
      "R Wiechula",
      "D Marcoionni"
    ],
    "abstract": "Abstract not available",
    "url": "https://doi.org/10.1097/01258363-200909000-00067",
    "bibtex": "@article{topic2009,\n  title={TOPIC 7 (the older person and improving care): evaluation},\n  author={R Wiechula and D Marcoionni},\n  year={2009},\n  journal={International Journal of Evidence-Based Healthcare},\n  doi={10.1097/01258363-200909000-00067}\n}",
    "year": 2009,
    "relevance_score": 0.3333333333333333,
    "source": "crossref",
    "citation_count": null,
    "doi": "10.1097/01258363-200909000-00067"
  },
  {
    "title": "A Scalable Approach to Benchmarking the In-Conversation Differential   Diagnostic Accuracy of a Health AI",
    "authors": [
      "Deep Bhatt",
      "Surya Ayyagari",
      "Anuruddh Mishra"
    ],
    "abstract": "Diagnostic errors in healthcare persist as a critical challenge, with increasing numbers of patients turning to online resources for health information. While AI-powered healthcare chatbots show promise, there exists no standardized and scalable framework for evaluating their diagnostic capabilities. This study introduces a scalable benchmarking methodology for assessing health AI systems and demonstrates its application through August, an AI-driven conversational chatbot. Our methodology employs 400 validated clinical vignettes across 14 medical specialties, using AI-powered patient actors to simulate realistic clinical interactions. In systematic testing, August achieved a top-one diagnostic accuracy of 81.8% (327/400 cases) and a top-two accuracy of 85.0% (340/400 cases), significantly outperforming traditional symptom checkers. The system demonstrated 95.8% accuracy in specialist referrals and required 47% fewer questions compared to conventional symptom checkers (mean 16 vs 29 questions), while maintaining empathetic dialogue throughout consultations. These findings demonstrate the potential of AI chatbots to enhance healthcare delivery, though implementation challenges remain regarding real-world validation and integration of objective clinical data. This research provides a reproducible framework for evaluating healthcare AI systems, contributing to the responsible development and deployment of AI in clinical settings.",
    "url": "http://arxiv.org/abs/2412.12538v1",
    "bibtex": "@article{a2024,\n  title={A Scalable Approach to Benchmarking the In-Conversation Differential   Diagnostic Accuracy of a Health AI},\n  author={Deep Bhatt and Surya Ayyagari and Anuruddh Mishra},\n  year={2024},\n  url={http://arxiv.org/abs/2412.12538v1},\n  note={arXiv preprint}\n}",
    "year": 2024,
    "relevance_score": 0.16666666666666666,
    "source": "arxiv",
    "citation_count": null,
    "doi": null
  },
  {
    "title": "Building AI Models of Patient-specific Drug Side Effect Predictions",
    "authors": [
      "Bharath Ramsundar",
      "Sandya Subramanian"
    ],
    "abstract": "Abstract not available",
    "url": "https://doi.org/10.1109/ieeeconf58974.2023.10404544",
    "bibtex": "@article{building2023,\n  title={Building AI Models of Patient-specific Drug Side Effect Predictions},\n  author={Bharath Ramsundar and Sandya Subramanian},\n  year={2023},\n  journal={2023 IEEE EMBS Special Topic Conference on Data Science and Engineering in Healthcare, Medicine and Biology},\n  doi={10.1109/ieeeconf58974.2023.10404544}\n}",
    "year": 2023,
    "relevance_score": 0.16666666666666666,
    "source": "crossref",
    "citation_count": null,
    "doi": "10.1109/ieeeconf58974.2023.10404544"
  },
  {
    "title": "Over-Relying on Reliance: Towards Realistic Evaluations of AI-Based   Clinical Decision Support",
    "authors": [
      "Venkatesh Sivaraman",
      "Katelyn Morrison",
      "Will Epperson",
      "Adam Perer"
    ],
    "abstract": "As AI-based clinical decision support (AI-CDS) is introduced in more and more aspects of healthcare services, HCI research plays an increasingly important role in designing for complementarity between AI and clinicians. However, current evaluations of AI-CDS often fail to capture when AI is and is not useful to clinicians. This position paper reflects on our work and influential AI-CDS literature to advocate for moving beyond evaluation metrics like Trust, Reliance, Acceptance, and Performance on the AI's task (what we term the \"trap\" of human-AI collaboration). Although these metrics can be meaningful in some simple scenarios, we argue that optimizing for them ignores important ways that AI falls short of clinical benefit, as well as ways that clinicians successfully use AI. As the fields of HCI and AI in healthcare develop new ways to design and evaluate CDS tools, we call on the community to prioritize ecologically valid, domain-appropriate study setups that measure the emergent forms of value that AI can bring to healthcare professionals.",
    "url": "http://arxiv.org/abs/2504.07423v1",
    "bibtex": "@article{over-relying2025,\n  title={Over-Relying on Reliance: Towards Realistic Evaluations of AI-Based   Clinical Decision Support},\n  author={Venkatesh Sivaraman and Katelyn Morrison and Will Epperson and Adam Perer},\n  year={2025},\n  url={http://arxiv.org/abs/2504.07423v1},\n  note={arXiv preprint}\n}",
    "year": 2025,
    "relevance_score": 0.0,
    "source": "arxiv",
    "citation_count": null,
    "doi": null
  }
]