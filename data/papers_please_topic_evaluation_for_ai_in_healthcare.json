[
  {
    "title": "IAC: A Framework for Enabling Patient Agency in the Use of AI-Enabled   Healthcare",
    "authors": [
      "Chinasa T. Okolo",
      "Michelle González Amador"
    ],
    "abstract": "In healthcare, the role of AI is continually evolving, and understanding the challenges its introduction poses on relationships between healthcare providers and patients will require a regulatory and behavioral approach that can provide a guiding base for all users involved. In this paper, we present IAC (Informing, Assessment, and Consent), a framework for evaluating patient response to the introduction of AI-enabled digital technologies in healthcare settings. We justify the need for IAC with a general introduction of the challenges with and perceived relevance of AI in human-welfare-centered fields, with an emphasis on the provision of healthcare. The framework is composed of three core principles that guide how healthcare practitioners can inform patients about the use of AI in their healthcare, how practitioners can assess patients' acceptability and comfortability with the use of AI, and how patient consent can be gained after this process. We propose that the principles composing this framework can be translated into guidelines that improve practitioner-patient relationships and, concurrently, patient agency regarding the use of AI in healthcare while broadening the discourse on this topic.",
    "url": "http://arxiv.org/abs/2111.04456v3",
    "bibtex": "@article{iac:2021,\n  title={IAC: A Framework for Enabling Patient Agency in the Use of AI-Enabled   Healthcare},\n  author={Chinasa T. Okolo and Michelle González Amador},\n  year={2021},\n  url={http://arxiv.org/abs/2111.04456v3},\n  note={arXiv preprint}\n}",
    "year": 2021,
    "relevance_score": 0.42857142857142855,
    "source": "arxiv",
    "citation_count": null,
    "doi": null
  },
  {
    "title": "Importance of User Control in Data-Centric Steering for Healthcare   Experts",
    "authors": [
      "Aditya Bhattacharya",
      "Simone Stumpf",
      "Katrien Verbert"
    ],
    "abstract": "As Artificial Intelligence (AI) becomes increasingly integrated into high-stakes domains like healthcare, effective collaboration between healthcare experts and AI systems is critical. Data-centric steering, which involves fine-tuning prediction models by improving training data quality, plays a key role in this process. However, little research has explored how varying levels of user control affect healthcare experts during data-centric steering. We address this gap by examining manual and automated steering approaches through a between-subjects, mixed-methods user study with 74 healthcare experts. Our findings show that manual steering, which grants direct control over training data, significantly improves model performance while maintaining trust and system understandability. Based on these findings, we propose design implications for a hybrid steering system that combines manual and automated approaches to increase user involvement during human-AI collaboration.",
    "url": "http://arxiv.org/abs/2506.18770v1",
    "bibtex": "@article{importance2025,\n  title={Importance of User Control in Data-Centric Steering for Healthcare   Experts},\n  author={Aditya Bhattacharya and Simone Stumpf and Katrien Verbert},\n  year={2025},\n  url={http://arxiv.org/abs/2506.18770v1},\n  note={arXiv preprint}\n}",
    "year": 2025,
    "relevance_score": 0.42857142857142855,
    "source": "arxiv",
    "citation_count": null,
    "doi": null
  },
  {
    "title": "Developing a Medical AI Ethics Framework: Integrating Ethical Principles with Healthcare Applications Using Topic Modelling",
    "authors": [
      "Oluwafeyifunmi Olunuga"
    ],
    "abstract": "Abstract not available",
    "url": "https://doi.org/10.22215/etd/2023-15586",
    "bibtex": "@article{developing2024,\n  title={Developing a Medical AI Ethics Framework: Integrating Ethical Principles with Healthcare Applications Using Topic Modelling},\n  author={Oluwafeyifunmi Olunuga},\n  year={2024},\n  doi={10.22215/etd/2023-15586}\n}",
    "year": 2024,
    "relevance_score": 0.42857142857142855,
    "source": "crossref",
    "citation_count": null,
    "doi": "10.22215/etd/2023-15586"
  },
  {
    "title": "Explainable AI (XAI) in Healthcare - Tools and Regulations",
    "authors": [
      "Paweł Raif",
      "Renata Suchanek-Raif",
      "Ewaryst Tkacz"
    ],
    "abstract": "Abstract not available",
    "url": "https://doi.org/10.1109/ieeeconf58974.2023.10405096",
    "bibtex": "@article{explainable2023,\n  title={Explainable AI (XAI) in Healthcare - Tools and Regulations},\n  author={Paweł Raif and Renata Suchanek-Raif and Ewaryst Tkacz},\n  year={2023},\n  journal={2023 IEEE EMBS Special Topic Conference on Data Science and Engineering in Healthcare, Medicine and Biology},\n  doi={10.1109/ieeeconf58974.2023.10405096}\n}",
    "year": 2023,
    "relevance_score": 0.42857142857142855,
    "source": "crossref",
    "citation_count": null,
    "doi": "10.1109/ieeeconf58974.2023.10405096"
  },
  {
    "title": "FUTURE-AI: Guiding Principles and Consensus Recommendations for   Trustworthy Artificial Intelligence in Medical Imaging",
    "authors": [
      "Karim Lekadir",
      "Richard Osuala",
      "Catherine Gallin",
      "Noussair Lazrak",
      "Kaisar Kushibar",
      "Gianna Tsakou",
      "Susanna Aussó",
      "Leonor Cerdá Alberich",
      "Kostas Marias",
      "Manolis Tsiknakis",
      "Sara Colantonio",
      "Nickolas Papanikolaou",
      "Zohaib Salahuddin",
      "Henry C Woodruff",
      "Philippe Lambin",
      "Luis Martí-Bonmatí"
    ],
    "abstract": "The recent advancements in artificial intelligence (AI) combined with the extensive amount of data generated by today's clinical systems, has led to the development of imaging AI solutions across the whole value chain of medical imaging, including image reconstruction, medical image segmentation, image-based diagnosis and treatment planning. Notwithstanding the successes and future potential of AI in medical imaging, many stakeholders are concerned of the potential risks and ethical implications of imaging AI solutions, which are perceived as complex, opaque, and difficult to comprehend, utilise, and trust in critical clinical applications. Addressing these concerns and risks, the FUTURE-AI framework has been proposed, which, sourced from a global multi-domain expert consensus, comprises guiding principles for increased trust, safety, and adoption for AI in healthcare. In this paper, we transform the general FUTURE-AI healthcare principles to a concise and specific AI implementation guide tailored to the needs of the medical imaging community. To this end, we carefully assess each building block of the FUTURE-AI framework consisting of (i) Fairness, (ii) Universality, (iii) Traceability, (iv) Usability, (v) Robustness and (vi) Explainability, and respectively define concrete best practices based on accumulated AI implementation experiences from five large European projects on AI in Health Imaging. We accompany our concrete step-by-step medical imaging development guide with a practical AI solution maturity checklist, thus enabling AI development teams to design, evaluate, maintain, and deploy technically, clinically and ethically trustworthy imaging AI solutions into clinical practice.",
    "url": "http://arxiv.org/abs/2109.09658v6",
    "bibtex": "@article{future-ai:2021,\n  title={FUTURE-AI: Guiding Principles and Consensus Recommendations for   Trustworthy Artificial Intelligence in Medical Imaging},\n  author={Karim Lekadir and Richard Osuala and Catherine Gallin and Noussair Lazrak and Kaisar Kushibar and Gianna Tsakou and Susanna Aussó and Leonor Cerdá Alberich and Kostas Marias and Manolis Tsiknakis and Sara Colantonio and Nickolas Papanikolaou and Zohaib Salahuddin and Henry C Woodruff and Philippe Lambin and Luis Martí-Bonmatí},\n  year={2021},\n  url={http://arxiv.org/abs/2109.09658v6},\n  note={arXiv preprint}\n}",
    "year": 2021,
    "relevance_score": 0.2857142857142857,
    "source": "arxiv",
    "citation_count": null,
    "doi": null
  },
  {
    "title": "Explanatory Debiasing: Involving Domain Experts in the Data Generation   Process to Mitigate Representation Bias in AI Systems",
    "authors": [
      "Aditya Bhattacharya",
      "Simone Stumpf",
      "Robin De Croon",
      "Katrien Verbert"
    ],
    "abstract": "Representation bias is one of the most common types of biases in artificial intelligence (AI) systems, causing AI models to perform poorly on underrepresented data segments. Although AI practitioners use various methods to reduce representation bias, their effectiveness is often constrained by insufficient domain knowledge in the debiasing process. To address this gap, this paper introduces a set of generic design guidelines for effectively involving domain experts in representation debiasing. We instantiated our proposed guidelines in a healthcare-focused application and evaluated them through a comprehensive mixed-methods user study with 35 healthcare experts. Our findings show that involving domain experts can reduce representation bias without compromising model accuracy. Based on our findings, we also offer recommendations for developers to build robust debiasing systems guided by our generic design guidelines, ensuring more effective inclusion of domain experts in the debiasing process.",
    "url": "http://arxiv.org/abs/2501.01441v2",
    "bibtex": "@article{explanatory2024,\n  title={Explanatory Debiasing: Involving Domain Experts in the Data Generation   Process to Mitigate Representation Bias in AI Systems},\n  author={Aditya Bhattacharya and Simone Stumpf and Robin De Croon and Katrien Verbert},\n  year={2024},\n  url={http://arxiv.org/abs/2501.01441v2},\n  note={arXiv preprint}\n}",
    "year": 2024,
    "relevance_score": 0.2857142857142857,
    "source": "arxiv",
    "citation_count": null,
    "doi": null
  },
  {
    "title": "TOPIC 7 (the older person and improving care): evaluation",
    "authors": [
      "R Wiechula",
      "D Marcoionni"
    ],
    "abstract": "Abstract not available",
    "url": "https://doi.org/10.1097/01258363-200909000-00067",
    "bibtex": "@article{topic2009,\n  title={TOPIC 7 (the older person and improving care): evaluation},\n  author={R Wiechula and D Marcoionni},\n  year={2009},\n  journal={International Journal of Evidence-Based Healthcare},\n  doi={10.1097/01258363-200909000-00067}\n}",
    "year": 2009,
    "relevance_score": 0.2857142857142857,
    "source": "crossref",
    "citation_count": null,
    "doi": "10.1097/01258363-200909000-00067"
  },
  {
    "title": "Building AI Models of Patient-specific Drug Side Effect Predictions",
    "authors": [
      "Bharath Ramsundar",
      "Sandya Subramanian"
    ],
    "abstract": "Abstract not available",
    "url": "https://doi.org/10.1109/ieeeconf58974.2023.10404544",
    "bibtex": "@article{building2023,\n  title={Building AI Models of Patient-specific Drug Side Effect Predictions},\n  author={Bharath Ramsundar and Sandya Subramanian},\n  year={2023},\n  journal={2023 IEEE EMBS Special Topic Conference on Data Science and Engineering in Healthcare, Medicine and Biology},\n  doi={10.1109/ieeeconf58974.2023.10404544}\n}",
    "year": 2023,
    "relevance_score": 0.14285714285714285,
    "source": "crossref",
    "citation_count": null,
    "doi": "10.1109/ieeeconf58974.2023.10404544"
  },
  {
    "title": "Over-Relying on Reliance: Towards Realistic Evaluations of AI-Based   Clinical Decision Support",
    "authors": [
      "Venkatesh Sivaraman",
      "Katelyn Morrison",
      "Will Epperson",
      "Adam Perer"
    ],
    "abstract": "As AI-based clinical decision support (AI-CDS) is introduced in more and more aspects of healthcare services, HCI research plays an increasingly important role in designing for complementarity between AI and clinicians. However, current evaluations of AI-CDS often fail to capture when AI is and is not useful to clinicians. This position paper reflects on our work and influential AI-CDS literature to advocate for moving beyond evaluation metrics like Trust, Reliance, Acceptance, and Performance on the AI's task (what we term the \"trap\" of human-AI collaboration). Although these metrics can be meaningful in some simple scenarios, we argue that optimizing for them ignores important ways that AI falls short of clinical benefit, as well as ways that clinicians successfully use AI. As the fields of HCI and AI in healthcare develop new ways to design and evaluate CDS tools, we call on the community to prioritize ecologically valid, domain-appropriate study setups that measure the emergent forms of value that AI can bring to healthcare professionals.",
    "url": "http://arxiv.org/abs/2504.07423v1",
    "bibtex": "@article{over-relying2025,\n  title={Over-Relying on Reliance: Towards Realistic Evaluations of AI-Based   Clinical Decision Support},\n  author={Venkatesh Sivaraman and Katelyn Morrison and Will Epperson and Adam Perer},\n  year={2025},\n  url={http://arxiv.org/abs/2504.07423v1},\n  note={arXiv preprint}\n}",
    "year": 2025,
    "relevance_score": 0.0,
    "source": "arxiv",
    "citation_count": null,
    "doi": null
  },
  {
    "title": "Give me an Easy Topic, Please: My Experience of Supervising Theses",
    "authors": [
      "Sajan Kumar Karn"
    ],
    "abstract": "<jats:p>Thesis writing is demanding in that it requires a great deal of time, patience, study, creativity, writing proficiency and also critical and analytical expertise on the part of researchers. Unfortunately, many of the beginners do not seem to understand the gravity of such a high level academic feat and consequently pose a lot of problems for thesis supervisors, guidance committee, university department, etc. This paper endeavors to scrutinize students' misconceptions and negligence again...",
    "url": "https://doi.org/10.3126/nelta.v14i1.3092",
    "bibtex": "@article{give1970,\n  title={Give me an Easy Topic, Please: My Experience of Supervising Theses},\n  author={Sajan Kumar Karn},\n  year={1970},\n  journal={Journal of NELTA},\n  doi={10.3126/nelta.v14i1.3092}\n}",
    "year": 1970,
    "relevance_score": 0.0,
    "source": "crossref",
    "citation_count": null,
    "doi": "10.3126/nelta.v14i1.3092"
  }
]